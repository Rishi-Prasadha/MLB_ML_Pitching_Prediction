{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports and Data Preprocessing\n",
    "\n",
    "Import data and do basics of removing extraneous data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initial imports\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from keras.utils import np_utils\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Verlander dataset \n",
    "\n",
    "verlander_df = pd.read_csv(Path(\"../resources/verlander_update.csv\"))\n",
    "\n",
    "display(verlander_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean dataset \n",
    "\n",
    "verlander_df = verlander_df.drop(columns=['des',\n",
    "'at_bat_number', \n",
    "'inning', \n",
    "'zone', \n",
    "'player_name', \n",
    "'batter', \n",
    "'pitcher', \n",
    "'events',\n",
    "'bb_type',\n",
    "'hit_location',\n",
    "'home_team',\n",
    "'away_team'])\n",
    "\n",
    "display(verlander_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode 1st, 2nd and 3rd bases with 1s and 0s\n",
    "\n",
    "# Fill NaN to 0 \n",
    "verlander_df['on_3b'] = verlander_df['on_3b'].fillna(0)\n",
    "verlander_df['on_2b'] = verlander_df['on_2b'].fillna(0)\n",
    "verlander_df['on_1b'] = verlander_df['on_1b'].fillna(0)\n",
    "\n",
    "# Change batter IDs to 1 \n",
    "verlander_df['on_3b'][verlander_df['on_3b'] > 0.0] = 1.0\n",
    "verlander_df['on_2b'][verlander_df['on_2b'] > 0.0] = 1.0\n",
    "verlander_df['on_1b'][verlander_df['on_1b'] > 0.0] = 1.0\n",
    "\n",
    "display(verlander_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill NaN in description column\n",
    "\n",
    "verlander_df['description'] = verlander_df['description'].fillna('nothing')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shift pitches so that model does not know the upcoming pitch \n",
    "\n",
    "verlander_df['pitch_name'] = verlander_df['pitch_name'].shift(-1).dropna()\n",
    "verlander_df['type'] = verlander_df['type'].shift(-1).dropna()\n",
    "\n",
    "display(verlander_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting batting score and fielding score to one column.\n",
    "# Positive number means fielding team is winning and negative number means batting team is winning. \n",
    "verlander_df['score_diff'] = verlander_df['fld_score'] - verlander_df['bat_score']\n",
    "\n",
    "\n",
    "# Drop batting score and fielding score columns now that you have the score differential\n",
    "verlander_df.drop(columns = ['bat_score', 'fld_score'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature engineering to count the number of pitches JV has thrown each outing\n",
    "\n",
    "verlander_df['ones'] = 1\n",
    "pitch_count_df = verlander_df[['game_date', 'ones']]\n",
    "pitch_count_df['pitch_count'] = pitch_count_df.groupby(['game_date']).cumcount(ascending = False)\n",
    "pitch_count_df['pitch_count'] = pitch_count_df['pitch_count'] + 1\n",
    "\n",
    "verlander_df = pd.concat([verlander_df, pitch_count_df['pitch_count']], join='inner', axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature engineering to change the ball and strike count into one column as a string\n",
    "\n",
    "verlander_df['count'] = verlander_df['balls'].astype(str) +'-'+ verlander_df['strikes'].astype(str)\n",
    "verlander_df.drop(columns=['balls', 'strikes'], inplace=True)\n",
    "verlander_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Processing \n",
    "\n",
    "Prepare data to be fed into model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into X and y \n",
    "\n",
    "X = verlander_df.drop(columns=['pitch_type', 'game_date'])\n",
    "y= verlander_df['pitch_type']\n",
    "\n",
    "display(y.value_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use get_dummies to encode categorical variables \n",
    "\n",
    "X = pd.get_dummies(X)\n",
    "\n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(y)\n",
    "encoded_y = encoder.transform(y)\n",
    "# convert integers to dummy variables (i.e. one hot encoded)\n",
    "dummy_y = np_utils.to_categorical(encoded_y)\n",
    "\n",
    "display(X.head())\n",
    "display(dummy_y)\n",
    "\n",
    "display(X.columns)\n",
    "\n",
    "# SL = index 3\n",
    "# CH = index 0\n",
    "# FF = index 2\n",
    "# CU = index 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, dummy_y, random_state=1)\n",
    "\n",
    "# X_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deep Learning/Neural Network Architecture\n",
    "\n",
    "Using the method from the module, the following basis is used to design the first iteration of the neural network: \n",
    "\n",
    "*the mean of the number of input features and the number of neurons in the output layer ((number of input features + number of neurons in output layer) / 2). Use a number close to this mean for the number of neurons in the first hidden layer. Repeat this pattern for subsequent hidden layers ((number of neurons in the prior hidden layer + number of neurons in output layer) / 2). Softmax is the activation for the output layer that is used for multi-class classification. Categorial cross entropy and predictive model accuracy are respectively the loss functions and metrics used for multi-class classification*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the Deep Learning Neural Network model\n",
    "\n",
    "nn_v0 = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Design the network architecture \n",
    "\n",
    "# Define the model - deep neural net\n",
    "number_input_features = len(X.columns)\n",
    "number_output = 4\n",
    "\n",
    "# Define hidden layers\n",
    "i = 0\n",
    "hidden_nodes_layer=(number_input_features+number_output)/2\n",
    "while hidden_nodes_layer/2 > 4:\n",
    "    if i == 0:\n",
    "        nn_v0.add(Dense(units=round(hidden_nodes_layer), input_dim=number_input_features, activation='relu'))\n",
    "        i+=1\n",
    "    else:\n",
    "        hidden_nodes_layer = (hidden_nodes_layer+number_output)/2\n",
    "        nn_v0.add(Dense(units=round(hidden_nodes_layer), activation='relu'))\n",
    "        i+=1\n",
    "\n",
    "# Define output layer\n",
    "nn_v0.add(Dense(units=number_output, activation='softmax'))\n",
    "\n",
    "# Compile the model\n",
    "nn_v0.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "display(nn_v0.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the data to the model\n",
    "\n",
    "model_v0 = nn_v0.fit(X_train, y_train, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the loss over epochs\n",
    "\n",
    "plt.plot(model_v0.history[\"loss\"])\n",
    "plt.title(\"Model V0 Training Loss Function\")\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the accuracy over epochs\n",
    "\n",
    "plt.plot(model_v0.history[\"accuracy\"])\n",
    "plt.title(\"Model V0 Training Accuracy\")\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate model on test set\n",
    "\n",
    "model_loss, model_accuracy = nn_v0.evaluate(\n",
    "    X_test, y_test, verbose=2\n",
    ")\n",
    "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Have the neural network cast its prediction on what pitch is next\n",
    "\n",
    "y_pred = nn_v0.predict(X_test)\n",
    "pred_final = np.argmax(y_pred, axis=1)\n",
    "\n",
    "# Translate target of test set into pitch type\n",
    "\n",
    "y_test_reverted = []\n",
    "for lists in y_test:\n",
    "    if lists[0] == 1:\n",
    "        y_test_reverted.append('CH')\n",
    "    elif lists[1] == 1:\n",
    "        y_test_reverted.append('CU')\n",
    "    elif lists[2] == 1:\n",
    "        y_test_reverted.append('FF')\n",
    "    else:\n",
    "        y_test_reverted.append('SL')\n",
    "\n",
    "# Translate results into pitch type\n",
    "\n",
    "y_pred_converted = []\n",
    "for numbers in pred_final:\n",
    "    if numbers == 0:\n",
    "        y_pred_converted.append('CH')\n",
    "    elif numbers == 1:\n",
    "        y_pred_converted.append('CU')\n",
    "    elif numbers == 2:\n",
    "        y_pred_converted.append('FF')\n",
    "    else: \n",
    "        y_pred_converted.append('SL')\n",
    "\n",
    "# Place results in dataframe\n",
    "\n",
    "final_results = pd.DataFrame({\n",
    "    'Predictions': y_pred_converted,\n",
    "    'Actual':  y_test_reverted})\n",
    "\n",
    "display(final_results.head())\n",
    "print(classification_report(final_results['Actual'], final_results['Predictions']))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Network Feature Importance Instance\n",
    "\n",
    "Using the Lime library, visualize the importance of features for an instance in the testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use Lime library to help visualize important features \n",
    "\n",
    "from lime import lime_tabular\n",
    "\n",
    "lime_explainer = lime_tabular.LimeTabularExplainer(\n",
    "    training_data = np.array(X_train), \n",
    "    feature_names = list(X_train.columns),\n",
    "    class_names=['CH', 'CU', 'FF', 'SL'],\n",
    "    mode='classification',\n",
    "    verbose = True, \n",
    "    random_state=1\n",
    ")\n",
    "\n",
    "lime_exp = lime_explainer.explain_instance(\n",
    "    data_row = X_test.iloc[0, :],\n",
    "    predict_fn = nn_v0.predict,\n",
    "    num_features=10 \n",
    ")\n",
    "\n",
    "lime_exp.as_pyplot_figure()\n",
    "# display(pd.DataFrame(lime_exp.as_list()))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimize the Model\n",
    "\n",
    "### Optimized Model 1\n",
    "Optimize the model by increasing the number of epochs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define the new, optimized model\n",
    "\n",
    "nn_v1 = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Design the network architecture \n",
    "\n",
    "# Define the model - deep neural net\n",
    "number_input_features = len(X.columns)\n",
    "number_output = 4\n",
    "\n",
    "# Define hidden layers\n",
    "i = 0\n",
    "hidden_nodes_layer=(number_input_features+number_output)/2\n",
    "while hidden_nodes_layer/2 > 4: \n",
    "    if i == 0:\n",
    "        nn_v1.add(Dense(units=round(hidden_nodes_layer), input_dim=number_input_features, activation='relu'))\n",
    "        i+=1\n",
    "    else:\n",
    "        hidden_nodes_layer = (hidden_nodes_layer+number_output)/2\n",
    "        nn_v1.add(Dense(units=round(hidden_nodes_layer), activation='relu'))\n",
    "        i+=1\n",
    "\n",
    "# Define output layer\n",
    "nn_v1.add(Dense(units=number_output, activation='softmax'))\n",
    "\n",
    "# Compile the model\n",
    "nn_v1.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "print(len(X.columns))\n",
    "display(nn_v1.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the data to the model\n",
    "\n",
    "model_v1 = nn_v1.fit(X_train, y_train, epochs=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the loss over epochs\n",
    "\n",
    "plt.plot(model_v1.history[\"loss\"])\n",
    "plt.title(\"Model V1 Training Loss Function\")\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the accuracy over epochs\n",
    "\n",
    "plt.plot(model_v1.history[\"accuracy\"])\n",
    "plt.title(\"Model V1 Training Accuracy Function\")\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate model on test set\n",
    "\n",
    "model_loss, model_accuracy = nn_v1.evaluate(\n",
    "    X_test, y_test, verbose=2\n",
    ")\n",
    "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Have the neural network cast its prediction on what pitch is next\n",
    "\n",
    "y_pred = nn_v1.predict(X_test)\n",
    "pred_final = np.argmax(y_pred, axis=1)\n",
    "\n",
    "# Translate results into pitch type\n",
    "\n",
    "y_pred_converted = []\n",
    "for numbers in pred_final:\n",
    "    if numbers == 0:\n",
    "        y_pred_converted.append('CH')\n",
    "    elif numbers == 1:\n",
    "        y_pred_converted.append('CU')\n",
    "    elif numbers == 2:\n",
    "        y_pred_converted.append('FF')\n",
    "    else: \n",
    "        y_pred_converted.append('SL')\n",
    "\n",
    "# Place results into dataframe\n",
    "\n",
    "final_results_v1 = pd.DataFrame({\n",
    "    'Predictions': y_pred_converted,\n",
    "    'Actual':  y_test_reverted})\n",
    "\n",
    "display(final_results_v1.head())\n",
    "print(classification_report(final_results_v1['Actual'], final_results_v1['Predictions']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimized Model 2\n",
    "\n",
    "From Keras, use the stochastic gradient descent (SGD) optimizer that is an iterative method for optimizing an objective function with suitable smoothness properties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model\n",
    "\n",
    "nn_v2 = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Design the network architecture \n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "tf.keras.optimizers.Adadelta()\n",
    "#from keras.optimizers import Adadelta\n",
    "# Define the model - deep neural net\n",
    "\n",
    "total_neurons = len(X.columns)*(2/3)\n",
    "number_input_features = len(X.columns)\n",
    "number_output = 4\n",
    "\n",
    "# Define hidden layers\n",
    "i = 0\n",
    "hidden_nodes_layer=(number_input_features+number_output)/2\n",
    "while hidden_nodes_layer/2 > 4: \n",
    "    if i == 0:\n",
    "        nn_v2.add(Dense(units=round(hidden_nodes_layer), input_dim=number_input_features, activation='relu'))\n",
    "        i+=1\n",
    "    else:\n",
    "        hidden_nodes_layer = (hidden_nodes_layer+number_output)/2\n",
    "        nn_v2.add(Dense(units=round(hidden_nodes_layer), activation='relu'))\n",
    "        i+=1\n",
    "\n",
    "# Define output layer\n",
    "nn_v2.add(Dense(units=number_output, activation='softmax'))\n",
    "\n",
    "# Compile the model\n",
    "nn_v2.compile(loss='categorical_crossentropy', optimizer='adadelta', metrics=['accuracy'])\n",
    "\n",
    "display(nn_v2.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the data to the model\n",
    "\n",
    "model_v2 = nn_v2.fit(X_train, y_train, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the loss over epochs\n",
    "\n",
    "plt.plot(model_v2.history[\"loss\"])\n",
    "plt.title(\"Model V2 Training Loss Function\")\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the accuracy over epochs\n",
    "\n",
    "plt.plot(model_v2.history[\"accuracy\"])\n",
    "plt.title(\"Model V2 Training Accuracy Function\")\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate model on test set\n",
    "\n",
    "model_loss, model_accuracy = nn_v2.evaluate(\n",
    "    X_test, y_test, verbose=2\n",
    ")\n",
    "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Have the neural network cast its prediction on what pitch is next\n",
    "\n",
    "y_pred = nn_v2.predict(X_test)\n",
    "pred_final = np.argmax(y_pred, axis=1)\n",
    "\n",
    "# Translate results into pitch type\n",
    "\n",
    "y_pred_converted = []\n",
    "for numbers in pred_final:\n",
    "    if numbers == 0:\n",
    "        y_pred_converted.append('CH')\n",
    "    elif numbers == 1:\n",
    "        y_pred_converted.append('CU')\n",
    "    elif numbers == 2:\n",
    "        y_pred_converted.append('FF')\n",
    "    else: \n",
    "        y_pred_converted.append('SL')\n",
    "\n",
    "# Put results into dataframe\n",
    "\n",
    "final_results_v2 = pd.DataFrame({\n",
    "    'Predictions': y_pred_converted,\n",
    "    'Actual':  y_test_reverted})\n",
    "\n",
    "display(final_results_v2.head())\n",
    "print(classification_report(final_results_v2['Actual'], final_results_v2['Predictions']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimized Model 3\n",
    "\n",
    "From Keras, use the stochastic gradient descent (SGD) optimizer that is an iterative method for optimizing an objective function with suitable smoothness properties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model\n",
    "\n",
    "nn_v3 = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Design the network architecture \n",
    "\n",
    "from keras.optimizers import SGD\n",
    "# Define the model - deep neural net\n",
    "\n",
    "number_input_features = len(X.columns)\n",
    "number_output = 4\n",
    "\n",
    "# Define hidden layers\n",
    "i = 0\n",
    "hidden_nodes_layer=(number_input_features+number_output)/2\n",
    "while hidden_nodes_layer/2 > 4: \n",
    "    if i == 0:\n",
    "        nn_v3.add(Dense(units=round(hidden_nodes_layer), input_dim=number_input_features, activation='relu'))\n",
    "        i+=1\n",
    "    else:\n",
    "        hidden_nodes_layer = (hidden_nodes_layer+number_output)/2\n",
    "        nn_v3.add(Dense(units=round(hidden_nodes_layer), activation='relu'))\n",
    "        i+=1\n",
    "\n",
    "# Define output layer\n",
    "nn_v3.add(Dense(units=number_output, activation='softmax'))\n",
    "\n",
    "# Compile the model\n",
    "nn_v3.compile(loss='categorical_crossentropy', optimizer='sgd', metrics=['accuracy'])\n",
    "\n",
    "display(nn_v3.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the data to the model\n",
    "\n",
    "model_v3 = nn_v3.fit(X_train, y_train, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the loss over epochs\n",
    "\n",
    "plt.plot(model_v3.history[\"loss\"])\n",
    "plt.title(\"Model V3 Training Loss Function\")\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the accuracy over epochs\n",
    "\n",
    "plt.plot(model_v3.history[\"accuracy\"])\n",
    "plt.title(\"Model V3 Training Accuracy Function\")\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate model on test set\n",
    "\n",
    "model_loss, model_accuracy = nn_v3.evaluate(\n",
    "    X_test, y_test, verbose=2\n",
    ")\n",
    "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Have the neural network cast its prediction on what pitch is next\n",
    "\n",
    "y_pred = nn_v3.predict(X_test)\n",
    "pred_final = np.argmax(y_pred, axis=1)\n",
    "\n",
    "# Translate results into pitch type\n",
    "\n",
    "y_pred_converted = []\n",
    "for numbers in pred_final:\n",
    "    if numbers == 0:\n",
    "        y_pred_converted.append('CH')\n",
    "    elif numbers == 1:\n",
    "        y_pred_converted.append('CU')\n",
    "    elif numbers == 2:\n",
    "        y_pred_converted.append('FF')\n",
    "    else: \n",
    "        y_pred_converted.append('SL')\n",
    "\n",
    "# Create into dataframe\n",
    "final_results_v3 = pd.DataFrame({\n",
    "    'Predictions': y_pred_converted,\n",
    "    'Actual':  y_test_reverted})\n",
    "\n",
    "display(final_results_v3.head())\n",
    "print(classification_report(final_results_v3['Actual'], final_results_v3['Predictions']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Field Testing\n",
    "\n",
    "Justin Verlander pitched against the Arizona Diamondbacks on the evening of September 28, 2022 at home. The data from that game was extracted from Baseball Savant and used to test the 4 models above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "field_df = pd.read_csv(Path(\"../resources/field_test_data.csv\"))\n",
    "\n",
    "field_df = field_df.loc[:,        ['pitch_type',\n",
    "                                 'pitch_name',\n",
    "                                   'game_date',\n",
    "                                   'description',\n",
    "                                #    'zone',\n",
    "                                   'stand',\n",
    "                                   'p_throws',\n",
    "                                   'type',\n",
    "                                   'balls',\n",
    "                                   'strikes',\n",
    "                                   'on_3b',\n",
    "                                   'on_2b',\n",
    "                                   'on_1b',\n",
    "                                   'outs_when_up',\n",
    "                                   'pitch_number',\n",
    "                                   'bat_score',\n",
    "                                   'fld_score',\n",
    "                                   'if_fielding_alignment',\n",
    "                                   'of_fielding_alignment'\n",
    "                                  ]]\n",
    "\n",
    "display(verlander_df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shift pitches so that model does not know the upcoming pitch \n",
    "\n",
    "field_df['pitch_name'] = field_df['pitch_name'].shift(-1).dropna()\n",
    "field_df['type'] = field_df['type'].shift(-1).dropna()\n",
    "\n",
    "display(field_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting batting score and fielding score to one column.\n",
    "# Positive number means fielding team is winning and negative number means batting team is winning. \n",
    "field_df['score_diff'] = field_df['fld_score'] - field_df['bat_score']\n",
    "\n",
    "\n",
    "# Drop batting score and fielding score columns now that you have the score differential\n",
    "field_df.drop(columns = ['bat_score', 'fld_score'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature engineering to count the number of pitches JV has thrown each outing\n",
    "\n",
    "field_df['ones'] = 1\n",
    "pitch_count_df = field_df[['game_date', 'ones']]\n",
    "pitch_count_df['pitch_count'] = pitch_count_df.groupby(['game_date']).cumcount(ascending = False)\n",
    "pitch_count_df['pitch_count'] = pitch_count_df['pitch_count'] + 1\n",
    "\n",
    "field_df = pd.concat([field_df, pitch_count_df['pitch_count']], join='inner', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature engineering to change the ball and strike count into one column as a string\n",
    "\n",
    "field_df['count'] = field_df['balls'].astype(str) +'-'+ field_df['strikes'].astype(str)\n",
    "field_df.drop(columns=['balls', 'strikes'], inplace=True)\n",
    "field_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode 1st, 2nd and 3rd bases with 1s and 0s\n",
    "\n",
    "# Fill NaN to 0 \n",
    "field_df['on_3b'] = field_df['on_3b'].fillna(0)\n",
    "field_df['on_2b'] = field_df['on_2b'].fillna(0)\n",
    "field_df['on_1b'] = field_df['on_1b'].fillna(0)\n",
    "\n",
    "# Change batter IDs to 1 \n",
    "field_df['on_3b'][field_df['on_3b'] > 0.0] = 1.0\n",
    "field_df['on_2b'][field_df['on_2b'] > 0.0] = 1.0\n",
    "field_df['on_1b'][field_df['on_1b'] > 0.0] = 1.0\n",
    "\n",
    "display(field_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into X and y \n",
    "\n",
    "X_real_testing = field_df.drop(columns=['pitch_type', 'game_date'])\n",
    "y_real_testing = field_df['pitch_type']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use get_dummies to encode categorical variables \n",
    "\n",
    "X_real_testing = pd.get_dummies(X_real_testing)\n",
    "\n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(y_real_testing)\n",
    "encoded_y_real = encoder.transform(y_real_testing)\n",
    "\n",
    "# convert integers to dummy variables (i.e. one hot encoded)\n",
    "dummy_y_real = np_utils.to_categorical(encoded_y_real)\n",
    "\n",
    "# if a parameter is not present in the game data, put in a column of 0s\n",
    "parameters_list = {\n",
    "    'stand_L',\n",
    "    'stand_R',\n",
    "    'if_fielding_alignment_Infield shift',\n",
    "    'if_fielding_alignment_Standard',\n",
    "    'if_fielding_alignment_Strategic',\n",
    "    'of_fielding_alignment_Standard',\n",
    "    'of_fielding_alignment_Strategic',\n",
    "    'description_foul_bunt',\n",
    "    'description_blocked_ball'\n",
    "}\n",
    "for string in parameters_list:\n",
    "    if string not in X_real_testing:\n",
    "        X_real_testing[string] = 0\n",
    "\n",
    "display(X_real_testing.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate model 1 on test set\n",
    "\n",
    "model_loss, model_accuracy = nn_v0.evaluate(\n",
    "    X_real_testing, dummy_y_real, verbose=2\n",
    ")\n",
    "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate model 2 on test set\n",
    "\n",
    "model_loss, model_accuracy = nn_v1.evaluate(\n",
    "    X_real_testing, dummy_y_real, verbose=2\n",
    ")\n",
    "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate model 3 on test set\n",
    "\n",
    "model_loss, model_accuracy = nn_v2.evaluate(\n",
    "    X_real_testing, dummy_y_real, verbose=2\n",
    ")\n",
    "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate model 4 on test set\n",
    "\n",
    "model_loss, model_accuracy = nn_v3.evaluate(\n",
    "    X_real_testing, dummy_y_real, verbose=2\n",
    ")\n",
    "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Have the neural network cast its prediction on what pitch is next\n",
    "\n",
    "y_pred_v0 = nn_v0.predict(X_real_testing)\n",
    "y_pred_v1 = nn_v1.predict(X_real_testing)\n",
    "y_pred_v2 = nn_v2.predict(X_real_testing)\n",
    "y_pred_v3 = nn_v3.predict(X_real_testing)\n",
    "\n",
    "pred_final_v0 = np.argmax(y_pred_v0, axis=1)\n",
    "pred_final_v1 = np.argmax(y_pred_v1, axis=1)\n",
    "pred_final_v2 = np.argmax(y_pred_v2, axis=1)\n",
    "pred_final_v3 = np.argmax(y_pred_v3, axis=1)\n",
    "\n",
    "# Translate target of test set into pitch type\n",
    "\n",
    "y_test_reverted = []\n",
    "for lists in y_test:\n",
    "    if lists[0] == 1:\n",
    "        y_test_reverted.append('CH')\n",
    "    elif lists[1] == 1:\n",
    "        y_test_reverted.append('CU')\n",
    "    elif lists[2] == 1:\n",
    "        y_test_reverted.append('FF')\n",
    "    else:\n",
    "        y_test_reverted.append('SL')\n",
    "\n",
    "# Place results in dataframe\n",
    "\n",
    "final_results_real = pd.DataFrame()\n",
    "\n",
    "# Translate results into pitch type\n",
    "\n",
    "for arrays in [pred_final_v0, pred_final_v1, pred_final_v2, pred_final_v3]:\n",
    "    y_pred_converted = []\n",
    "    for numbers in arrays:\n",
    "        if numbers == 0:\n",
    "            y_pred_converted.append('CH')\n",
    "        elif numbers == 1:\n",
    "            y_pred_converted.append('CU')\n",
    "        elif numbers == 2:\n",
    "            y_pred_converted.append('FF')\n",
    "        else: \n",
    "            y_pred_converted.append('SL')\n",
    "    y_pred_series = pd.DataFrame(y_pred_converted)\n",
    "    final_results_real = pd.concat([final_results_real, y_pred_series], axis=1)\n",
    "\n",
    "final_results_real = pd.concat([final_results_real, y_real_testing], axis=1)\n",
    "final_results_real.columns = ['Model 1 (v0) Pred', 'Model 2 (v1) Pred', 'Model 3 (v2) Pred', 'Model 4 (v3) Pred', 'Actual']\n",
    "\n",
    "display(final_results_real)\n",
    "print(classification_report(final_results_real['Actual'], final_results_real['Model 1 (v0) Pred']))\n",
    "print(classification_report(final_results_real['Actual'], final_results_real['Model 2 (v1) Pred']))\n",
    "print(classification_report(final_results_real['Actual'], final_results_real['Model 3 (v2) Pred']))\n",
    "print(classification_report(final_results_real['Actual'], final_results_real['Model 4 (v3) Pred']))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('dev')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "4396f389b93e7269692bd3bea4c62813bbe379469bde939b058805f538feec11"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
